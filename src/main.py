import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
from datasets import load_dataset
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import math, random
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import json
import argparse

from Multi_head import MultiHeadAttention
from Position_wise_FFN import PositionwiseFFN
from LayerNorm import ManualResidualLayerNorm, ManualLayerNorm
from Positional_encoding import OriginalTransformerPositionalEncoding

# æ·»åŠ éšæœºç§å­è®¾ç½®å‡½æ•°
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

# ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
os.makedirs('results', exist_ok=True)

# ===================== æ•°æ®é›†å®šä¹‰ =====================
class IWSLTDataset(Dataset):
    def __init__(self, src_path, tgt_path, block_size=64):
        with open(src_path, 'r', encoding='utf-8') as f:
            src_lines = [line.strip() for line in f.readlines() if line.strip()]
        with open(tgt_path, 'r', encoding='utf-8') as f:
            tgt_lines = [line.strip() for line in f.readlines() if line.strip()]

        assert len(src_lines) == len(tgt_lines), "æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€æ–‡ä»¶è¡Œæ•°ä¸åŒ¹é…"
        self.block_size = block_size
        self.data = list(zip(src_lines, tgt_lines))
        
        # æ”¹ä¸ºå­—ç¬¦çº§å¤„ç†ï¼Œä¸ç¬¬ä¸€æ®µä»£ç ä¸€è‡´
        all_text = "".join(src_lines + tgt_lines)
        chars = sorted(set(all_text))
        self.vocab = {"<pad>": 0, "<bos>": 1, "<eos>": 2, "<unk>": 3}
        for i, char in enumerate(chars):
            self.vocab[char] = i + 4  # ä»4å¼€å§‹ï¼Œé¿å¼€ç‰¹æ®Šæ ‡è®°
        
        self.vocab_size = len(self.vocab)
        self.pad_idx = 0
        self.bos_idx = 1
        self.eos_idx = 2
        self.unk_idx = 3

    def encode(self, text):
        # å­—ç¬¦çº§ç¼–ç 
        ids = [self.vocab.get(char, self.unk_idx) for char in text]
        ids = [self.bos_idx] + ids + [self.eos_idx]
        
        # å¡«å……æˆ–æˆªæ–­
        if len(ids) < self.block_size:
            ids += [self.pad_idx] * (self.block_size - len(ids))
        else:
            ids = ids[:self.block_size]
        return torch.tensor(ids)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        src, tgt = self.data[idx]
        return self.encode(src), self.encode(tgt)

# ===================== Transformer æ¨¡å— =====================
class TransformerEncoderLayer(nn.Module):
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1, ablation=None):
        super().__init__()
        self.self_attn = MultiHeadAttention(d_model, num_heads)
        self.ffn = PositionwiseFFN(d_model, d_ff)
        self.norm1 = ManualLayerNorm(d_model)
        self.norm2 = ManualLayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
        self.ablation = ablation

    def forward(self, x, mask=None):
        attn_out = self.self_attn(x, x, x, mask)
        if self.ablation == "residual":
            x = self.norm1(self.dropout(attn_out))
        else:
            x = self.norm1(x + self.dropout(attn_out))

        ffn_out = self.ffn(x)
        if self.ablation == "residual":
            x = self.norm2(self.dropout(ffn_out))
        else:
            x = self.norm2(x + self.dropout(ffn_out))
        return x


class TransformerDecoderLayer(nn.Module):
    def __init__(self, d_model, num_heads, d_ff, dropout=0.1, ablation=None):
        super().__init__()
        self.self_attn = MultiHeadAttention(d_model, num_heads)
        self.cross_attn = MultiHeadAttention(d_model, num_heads)
        self.ffn = PositionwiseFFN(d_model, d_ff)
        self.norm1 = ManualLayerNorm(d_model)
        self.norm2 = ManualLayerNorm(d_model)
        self.norm3 = ManualLayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
        self.ablation = ablation

    def forward(self, x, enc_out=None, src_mask=None, tgt_mask=None):
        attn_out = self.self_attn(x, x, x, tgt_mask)
        if self.ablation == "residual":
            x = self.norm1(self.dropout(attn_out))
        else:
            x = self.norm1(x + self.dropout(attn_out))

        if enc_out is not None:
            cross_out = self.cross_attn(x, enc_out, enc_out, src_mask)
            if self.ablation == "residual":
                x = self.norm2(self.dropout(cross_out))
            else:
                x = self.norm2(x + self.dropout(cross_out))

        ffn_out = self.ffn(x)
        if self.ablation == "residual":
            x = self.norm3(self.dropout(ffn_out))
        else:
            x = self.norm3(x + self.dropout(ffn_out))
        return x


class TransformerSeq2Seq(nn.Module):
    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=64, num_heads=2, d_ff=128,
                 num_layers=1, max_seq_length=64, dropout=0.1, ablation=None):
        super().__init__()
        self.src_embed = nn.Embedding(src_vocab_size, d_model)
        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)
        self.ablation = ablation
        
        # ç»Ÿä¸€ä½ç½®ç¼–ç æ¥å£ï¼Œæ·»åŠ max_seq_lengthå‚æ•°
        if ablation == "posenc":
            self.pos_encoding = nn.Identity()
        else:
            self.pos_encoding = OriginalTransformerPositionalEncoding(d_model, max_seq_length)  # æ·»åŠ max_seq_length

        if ablation == "encoder":
            self.encoder = None
        else:
            self.encoder = nn.ModuleList([
                TransformerEncoderLayer(d_model, num_heads, d_ff, dropout, ablation=ablation)
                for _ in range(num_layers)
            ])

        self.decoder = nn.ModuleList([
            TransformerDecoderLayer(d_model, num_heads, d_ff, dropout, ablation=ablation)
            for _ in range(num_layers)
        ])
        self.fc_out = nn.Linear(d_model, tgt_vocab_size)

    def forward(self, src, tgt):
        # æ·»åŠ ç¼©æ”¾å› å­ï¼Œä¸ç¬¬ä¸€æ®µä»£ç ç»Ÿä¸€
        src = self.src_embed(src) * math.sqrt(self.src_embed.embedding_dim)
        tgt = self.tgt_embed(tgt) * math.sqrt(self.tgt_embed.embedding_dim)
        
        src = self.pos_encoding(src)
        tgt = self.pos_encoding(tgt)

        if self.encoder is not None:
            for layer in self.encoder:
                src = layer(src)

        enc_out = src if self.encoder is not None else None

        for layer in self.decoder:
            tgt = layer(tgt, enc_out)
        return self.fc_out(tgt)

# ===================== æ”¹è¿›çš„ç»˜å›¾å‡½æ•° =====================
def plot_ablation_comparison(ablation_results):
    """ç»˜åˆ¶æ¶ˆèå®éªŒå¯¹æ¯”å›¾"""
    plt.figure(figsize=(15, 5))
    
    # æŸå¤±å¯¹æ¯”
    plt.subplot(1, 3, 1)
    for name, results in ablation_results.items():
        plt.plot(results['val_losses'], label=name, marker='o')
    plt.title('Validation Loss Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # å›°æƒ‘åº¦å¯¹æ¯”
    plt.subplot(1, 3, 2)
    for name, results in ablation_results.items():
        plt.plot(results['val_ppls'], label=name, marker='o')
    plt.title('Validation Perplexity Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Perplexity')
    plt.legend()
    plt.grid(True)
    
    # æœ€ç»ˆæ€§èƒ½æŸ±çŠ¶å›¾
    plt.subplot(1, 3, 3)
    final_ppls = [results['val_ppls'][-1] for results in ablation_results.values()]
    names = list(ablation_results.keys())
    colors = ['blue', 'red', 'green', 'orange', 'purple']
    bars = plt.bar(names, final_ppls, color=colors[:len(names)])
    plt.title('Final Performance Comparison')
    plt.ylabel('Final Perplexity')
    plt.xticks(rotation=45)
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, ppl in zip(bars, final_ppls):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                f'{ppl:.2f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('results/ablation_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_ablation_impact(ablation_results):
    """æ˜¾ç¤ºå„ç»„ä»¶å¯¹æ€§èƒ½çš„å½±å“ç¨‹åº¦"""
    if 'none' not in ablation_results:
        print("âš ï¸ æ²¡æœ‰åŸºå‡†æ¨¡å‹(none)ï¼Œæ— æ³•è®¡ç®—æ€§èƒ½å½±å“")
        return
        
    baseline_ppl = ablation_results['none']['val_ppls'][-1]
    
    impacts = {}
    for name, results in ablation_results.items():
        if name != 'none':
            final_ppl = results['val_ppls'][-1]
            degradation = ((final_ppl - baseline_ppl) / baseline_ppl) * 100
            impacts[name] = degradation
    
    if not impacts:
        return
        
    # ç»˜åˆ¶å½±å“ç¨‹åº¦å›¾
    plt.figure(figsize=(10, 6))
    names = list(impacts.keys())
    degradations = list(impacts.values())
    
    colors = ['red' if x > 0 else 'green' for x in degradations]
    bars = plt.bar(names, degradations, color=colors, alpha=0.7)
    
    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    plt.title('Performance Impact of Ablated Components')
    plt.ylabel('Performance Degradation (%)')
    plt.xlabel('Ablated Components')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, deg in zip(bars, degradations):
        plt.text(bar.get_x() + bar.get_width()/2, deg + (1 if deg > 0 else -3), 
                f'{deg:+.1f}%', ha='center', va='bottom' if deg > 0 else 'top',
                fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('results/ablation_impact.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_ablation_report(ablation_results):
    """ç”Ÿæˆè¯¦ç»†çš„æ¶ˆèå®éªŒæŠ¥å‘Š"""
    print("=" * 60)
    print("            TRANSFORMER æ¶ˆèå®éªŒåˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    if 'none' not in ablation_results:
        print("âš ï¸ æ²¡æœ‰åŸºå‡†æ¨¡å‹(none)ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´æŠ¥å‘Š")
        return
        
    baseline = ablation_results['none']
    baseline_final_ppl = baseline['val_ppls'][-1]
    
    print(f"\nğŸ“Š åŸºå‡†æ¨¡å‹ (å®Œæ•´Transformer) æœ€ç»ˆæ€§èƒ½:")
    print(f"  - éªŒè¯é›†å›°æƒ‘åº¦: {baseline_final_ppl:.2f}")
    print(f"  - æœ€ç»ˆæŸå¤±: {baseline['val_losses'][-1]:.4f}")
    
    print("\nğŸ”¬ å„æ¶ˆèè®¾ç½®æ€§èƒ½å¯¹æ¯”:")
    print("-" * 60)
    print(f"{'æ¶ˆèç±»å‹':<12} {'æœ€ç»ˆå›°æƒ‘åº¦':<12} {'æ€§èƒ½ä¸‹é™%':<12} {'æ”¶æ•›é€Ÿåº¦':<10}")
    print("-" * 60)
    
    impacts = {}
    for name, results in ablation_results.items():
        if name == 'none':
            continue
            
        final_ppl = results['val_ppls'][-1]
        degradation = ((final_ppl - baseline_final_ppl) / baseline_final_ppl) * 100
        impacts[name] = degradation
        
        # ç®€å•è¯„ä¼°æ”¶æ•›é€Ÿåº¦ï¼ˆæœ€å3ä¸ªepochçš„å¹³å‡æ”¹è¿›ï¼‰
        if len(results['val_ppls']) >= 3:
            last_3_improvement = np.mean(np.diff(results['val_ppls'][-3:]))
            convergence = "æ…¢" if last_3_improvement > -0.1 else "å¿«"
        else:
            convergence = "æœªçŸ¥"
        
        print(f"{name:<12} {final_ppl:<12.2f} {degradation:<12.1f} {convergence:<10}")
    
    if impacts:
        print("\nğŸ’¡ å…³é”®å‘ç°:")
        worst_component = max(impacts, key=impacts.get)
        best_component = min(impacts, key=impacts.get)
        print(f"1. æœ€é‡è¦çš„ç»„ä»¶: {worst_component} (å½±å“: {impacts[worst_component]:+.1f}%)")
        print(f"2. å¯¹æ€§èƒ½å½±å“æœ€å°çš„ç»„ä»¶: {best_component} (å½±å“: {impacts[best_component]:+.1f}%)")
    
    print("\n" + "=" * 60)

def plot_individual_training_curves(ablation_results, ablation_type):
    """ç»˜åˆ¶å•ä¸ªæ¶ˆèå®éªŒçš„è®­ç»ƒæ›²çº¿"""
    if ablation_type not in ablation_results:
        return
        
    results = ablation_results[ablation_type]
    plt.figure(figsize=(10, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(results['train_losses'], label="Train Loss", marker='o')
    plt.plot(results['val_losses'], label="Val Loss", marker='o')
    plt.legend()
    plt.title(f"{ablation_type} - Loss Curve")
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(results['train_ppls'], label="Train PPL", marker='o')
    plt.plot(results['val_ppls'], label="Val PPL", marker='o')
    plt.legend()
    plt.title(f"{ablation_type} - Perplexity Curve")
    plt.xlabel('Epoch')
    plt.ylabel('Perplexity')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(f"results/training_curves_{ablation_type}.png", dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…æ˜¾ç¤º

# ===================== è®­ç»ƒå‡½æ•° =====================
def train_model(ablation_type, train_loader, val_loader, vocab_size, device, epochs=5):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹å¹¶è¿”å›ç»“æœ"""
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒæ¶ˆèå®éªŒ: {ablation_type}")
    
    model = TransformerSeq2Seq(
        src_vocab_size=vocab_size,
        tgt_vocab_size=vocab_size,
        ablation=ablation_type
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    train_losses, val_losses, train_ppls, val_ppls = [], [], [], []
    
    for epoch in range(1, epochs + 1):
        print(f"\n===== Epoch {epoch} =====")
        model.train()
        total_loss = 0
        
        for src, tgt in tqdm(train_loader, desc=f"Epoch {epoch}"):
            src, tgt = src.to(device), tgt.to(device)
            tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]
            logits = model(src, tgt_in)
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)
            optimizer.step()
            total_loss += loss.item()
        
        avg_loss = total_loss / len(train_loader)
        ppl = math.exp(avg_loss)
        train_losses.append(avg_loss)
        train_ppls.append(ppl)
        print(f"Train Loss: {avg_loss:.4f}, PPL: {ppl:.2f}")
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for src, tgt in val_loader:
                src, tgt = src.to(device), tgt.to(device)
                tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]
                logits = model(src, tgt_in)
                loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tgt_out.reshape(-1))
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        val_ppl = math.exp(avg_val_loss)
        val_losses.append(avg_val_loss)
        val_ppls.append(val_ppl)
        print(f"Val Loss: {avg_val_loss:.4f}, PPL: {val_ppl:.2f}")
    
    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), f"results/transformer_ablation_{ablation_type}.pth")
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ï¼šresults/transformer_ablation_{ablation_type}.pth")
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_ppls': train_ppls,
        'val_ppls': val_ppls
    }

# ===================== ä¸»ç¨‹åºå…¥å£ =====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Transformeræ¶ˆèå®éªŒ')
    parser.add_argument("--ablation", type=str, default="all",
                        choices=["none", "posenc", "residual", "encoder", "all"],
                        help="é€‰æ‹©æ¶ˆèç±»å‹æˆ–'all'è¿è¡Œæ‰€æœ‰")
    parser.add_argument("--epochs", type=int, default=5, help="è®­ç»ƒå‘¨æœŸæ•°")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    print(f"ğŸ”§ è®¾ç½®éšæœºç§å­: {args.seed}")
    
    # ç¡®å®šè¦è¿è¡Œçš„æ¶ˆèå®éªŒ
    if args.ablation == "all":
        ablation_types = ["none", "posenc", "residual", "encoder"]
    else:
        ablation_types = [args.ablation]
    
    print(f"ğŸ”¬ è¿è¡Œçš„æ¶ˆèå®éªŒ: {ablation_types}")
    print(f"â° æ¯ä¸ªå®éªŒè®­ç»ƒå‘¨æœŸ: {args.epochs}")
    
    # æ•°æ®å‡†å¤‡
    data_dir = r'C:\D\å¤§æ¨¡å‹\IWSLT2017'
    block_size = 64
    
    train_de, train_en, val_de, val_en = None, None, None, None
    for f in os.listdir(data_dir):
        if 'train' in f and f.endswith('.de') and '.xml' not in f:
            train_de = os.path.join(data_dir, f)
        elif 'train' in f and f.endswith('.en') and '.xml' not in f:
            train_en = os.path.join(data_dir, f)
        elif 'dev2010' in f and f.endswith('.de') and '.xml' not in f:
            val_de = os.path.join(data_dir, f)
        elif 'dev2010' in f and f.endswith('.en') and '.xml' not in f:
            val_en = os.path.join(data_dir, f)
    
    if not train_de or not train_en:
        raise FileNotFoundError("æ‰¾ä¸åˆ° IWSLT2017 è®­ç»ƒé›†æ–‡ä»¶")
    
    # åˆ›å»ºå®Œæ•´è®­ç»ƒæ•°æ®é›†
    full_train_dataset = IWSLTDataset(train_de, train_en, block_size)
    vocab_size = full_train_dataset.vocab_size
    
    if val_de and val_en:
        val_dataset = IWSLTDataset(val_de, val_en, block_size)
        train_dataset = full_train_dataset
    else:
        train_size = int(0.9 * len(full_train_dataset))
        val_size = len(full_train_dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(
            full_train_dataset, [train_size, val_size]
        )
        print("ä»è®­ç»ƒé›†åˆ’åˆ†éªŒè¯é›†")
    
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
    ablation_results = {}
    
    for ablation_type in ablation_types:
        results = train_model(ablation_type, train_loader, val_loader, vocab_size, device, args.epochs)
        ablation_results[ablation_type] = results
        
        # ä¸ºæ¯ä¸ªå®éªŒç»˜åˆ¶å•ç‹¬çš„æ›²çº¿
        plot_individual_training_curves(ablation_results, ablation_type)
    
    # å¦‚æœæœ‰å¤šä¸ªå®éªŒï¼Œç»˜åˆ¶å¯¹æ¯”å›¾
    if len(ablation_results) > 1:
        print("\nğŸ“ˆ ç”Ÿæˆæ¶ˆèå®éªŒå¯¹æ¯”å›¾...")
        plot_ablation_comparison(ablation_results)
        plot_ablation_impact(ablation_results)
        generate_ablation_report(ablation_results)
        
        # ä¿å­˜ç»“æœä»¥ä¾¿åç»­åˆ†æ
        with open('results/ablation_results.json', 'w') as f:
            # è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼
            serializable_results = {}
            for k, v in ablation_results.items():
                serializable_results[k] = {k2: [float(x) for x in v2] for k2, v2 in v.items()}
            json.dump(serializable_results, f, indent=2)
        print("âœ… ç»“æœå·²ä¿å­˜åˆ°: results/ablation_results.json")
    
    print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")